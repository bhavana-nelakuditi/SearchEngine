{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d4a15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Bhavana Nelakuditi\n",
    "# UIN: 667225823\n",
    "\n",
    "from tkinter import *\n",
    "import pickle\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import webbrowser\n",
    "#from ipynb.fs.full.Website_PreProcessing import tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55bc566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_directory = \"PickleFiles/\"\n",
    "pickle_pages_lens = open(pickle_directory+\"pages_lens.pickle\",\"rb\")\n",
    "pages_lens = pickle.load(pickle_pages_lens)\n",
    "\n",
    "pickle_idf = open(pickle_directory+\"idf.pickle\",\"rb\")\n",
    "idf = pickle.load(pickle_idf)\n",
    "\n",
    "pickle_tf_idf = open(pickle_directory+\"tf_idf.pickle\",\"rb\")\n",
    "tf_idf = pickle.load(pickle_tf_idf)\n",
    "\n",
    "pickle_url = open(pickle_directory + 'pages_crawled.pickle', 'rb')\n",
    "urls = pickle.load(pickle_url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef608f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"stopwords.txt\", 'r')\n",
    "stopwords=f.read()\n",
    "stopwords = stopwords.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e7c2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(data):\n",
    "    \n",
    "    #Removing SGML tags\n",
    "    data = re.sub(r'<.*?>','',data)\n",
    "    #remove punctuation, turns it to lower case\n",
    "    data = removePunctuation(data)\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    \n",
    "    # Removing numbers\n",
    "    data = re.sub(re.compile('[0-9]'), '', data)\n",
    "    \n",
    "    \n",
    "    #used split fucntion to tokenise the data on whitespace\n",
    "    tokens = data.split()   \n",
    "    return tokens\n",
    "\n",
    "def removePunctuation(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "# Stemming each word\n",
    "def implement_stemmer(token):\n",
    "    sno = nltk.stem.SnowballStemmer('english')\n",
    "    return sno.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d972fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(query, doc_lens):\n",
    "    similarity_scores = {}\n",
    "    query_len = 0\n",
    "    query_weights = {}\n",
    "    \n",
    "    query_dict = Counter(query)\n",
    "    \n",
    "    for token in query_dict.keys():\n",
    "        token_tf = query_dict[token] / query_dict.most_common(1)[0][1]\n",
    "        query_weights[token] = token_tf * idf.get(token,0)\n",
    "        query_len += query_weights[token] ** 2\n",
    "    \n",
    "    query_len = math.sqrt(query_len)\n",
    "\n",
    "    for token in query:\n",
    "        token_weight = query_weights.get(token)\n",
    "        if token_weight:\n",
    "            for page in tf_idf[token].keys():\n",
    "                similarity_scores[page] = similarity_scores.get(page,0) + (tf_idf[token][page] * token_weight)\n",
    "   \n",
    "    for page in similarity_scores:\n",
    "        similarity_scores[page] = similarity_scores[page] / (doc_lens[page] * query_len)\n",
    "    return similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "825c7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pages(count,webpages):\n",
    "    url_list = []\n",
    "    for i in range(count, count+10):\n",
    "        try:\n",
    "            url_no = int(webpages[i][0])\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(\"\\n No more results found !!\")\n",
    "            break\n",
    "        if urls.get(url_no, None):\n",
    "            url_list.append(urls.get(url_no))\n",
    "            #print(i+1,urls.get(url_no))\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "500b1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "current_result = []\n",
    "def callback(event):\n",
    "    webbrowser.open_new(event.widget.cget('text'))\n",
    "\n",
    "def searched():\n",
    "    children = window.winfo_children()\n",
    "    for child in children:\n",
    "        if str(type(child)) == \"<class 'tkinter.Frame'>\":\n",
    "            child.destroy()\n",
    "    frame = Frame(window)\n",
    "    \n",
    "    query = txt.get()\n",
    "    query_tokens = []\n",
    "    processed_query = tokenize_text(query)\n",
    "    for i in processed_query:\n",
    "            if len(i) > 2 and i not in stopwords:\n",
    "                stemmed_word = implement_stemmer(i)\n",
    "                if stemmed_word not in stopwords:\n",
    "                    query_tokens.append(stemmed_word)\n",
    "    print(\"Query tokens \", query_tokens)\n",
    "\n",
    "    similar_pages = cosine_similarity(query_tokens, pages_lens)\n",
    "    sorted_pages = sorted(similar_pages.items(), key= lambda x: x[1], reverse=True)\n",
    "    global current_result\n",
    "    current_result = sorted_pages\n",
    "    links = display_pages(count,sorted_pages)\n",
    "    \n",
    "    print(sorted_pages[:10])\n",
    "    \n",
    "    if len(links) == 0:\n",
    "        link = Label(frame, text=\"There are no results for this query.\")\n",
    "        link.pack()\n",
    "    else:\n",
    "        page_limit = 10\n",
    "        if len(links) < 10:\n",
    "            page_limit = len(links)\n",
    "        current_result = current_result[page_limit:]\n",
    "        for i in range(page_limit):\n",
    "            link = Label(frame, text=(links[i]), fg='blue', cursor='hand2')\n",
    "            link.pack()\n",
    "            link.bind(\"<Button-1>\", callback)\n",
    "    frame.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52c6263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_results():\n",
    "    children = window.winfo_children()\n",
    "    for child in children:\n",
    "        if str(type(child)) == \"<class 'tkinter.Frame'>\":\n",
    "            child.destroy()\n",
    "    frame = Frame(window)\n",
    "    global current_result\n",
    "    links = display_pages(0,current_result)\n",
    "    if len(current_result) < 10:\n",
    "        link = Label(frame, text=\"There are no results for this query.\")\n",
    "        link.pack()\n",
    "    else:\n",
    "        page_limit = 10\n",
    "        if len(current_result) < page_limit:\n",
    "            page_limit = len(links)\n",
    "        current_result = current_result[page_limit:]\n",
    "        for i in range(page_limit):\n",
    "            link = Label(frame, text=(links[i]), fg='blue', cursor='hand2')\n",
    "            link.pack()\n",
    "            link.bind(\"<Button-1>\", callback)\n",
    "    frame.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c93644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query tokens  ['librari']\n",
      "[('3494', 1.2691477540495783e-05), ('2511', 1.236266302135143e-05), ('5631', 1.2187701847546686e-05), ('4814', 1.0716871039461843e-05), ('5565', 9.263848404813975e-06), ('5537', 9.24934680245215e-06), ('5534', 9.184862314902032e-06), ('5529', 8.979551623598897e-06), ('5523', 8.804329940662064e-06), ('2246', 8.771321632147874e-06)]\n",
      "Query tokens  ['librari']\n",
      "[('3494', 1.2691477540495783e-05), ('2511', 1.236266302135143e-05), ('5631', 1.2187701847546686e-05), ('4814', 1.0716871039461843e-05), ('5565', 9.263848404813975e-06), ('5537', 9.24934680245215e-06), ('5534', 9.184862314902032e-06), ('5529', 8.979551623598897e-06), ('5523', 8.804329940662064e-06), ('2246', 8.771321632147874e-06)]\n",
      "Query tokens  ['cornelia']\n",
      "\n",
      " No more results found !!\n",
      "[('3981', 0.6902616683533176), ('3600', 0.2691350688768878), ('4181', 0.2691350688768878), ('96', 0.09705109560060898), ('1302', 0.07855865093109975), ('885', 0.0735489291663856), ('1204', 4.419700649595107e-05), ('4222', 2.324598681620935e-05)]\n",
      "Query tokens  ['cornelia']\n",
      "\n",
      " No more results found !!\n",
      "[('3981', 0.6902616683533176), ('3600', 0.2691350688768878), ('4181', 0.2691350688768878), ('96', 0.09705109560060898), ('1302', 0.07855865093109975), ('885', 0.0735489291663856), ('1204', 4.419700649595107e-05), ('4222', 2.324598681620935e-05)]\n",
      "Query tokens  ['cornelia']\n",
      "\n",
      " No more results found !!\n",
      "[('3981', 0.6902616683533176), ('3600', 0.2691350688768878), ('4181', 0.2691350688768878), ('96', 0.09705109560060898), ('1302', 0.07855865093109975), ('885', 0.0735489291663856), ('1204', 4.419700649595107e-05), ('4222', 2.324598681620935e-05)]\n",
      "\n",
      " No more results found !!\n",
      "Query tokens  ['cornelia']\n",
      "\n",
      " No more results found !!\n",
      "[('3981', 0.6902616683533176), ('3600', 0.2691350688768878), ('4181', 0.2691350688768878), ('96', 0.09705109560060898), ('1302', 0.07855865093109975), ('885', 0.0735489291663856), ('1204', 4.419700649595107e-05), ('4222', 2.324598681620935e-05)]\n",
      "Query tokens  ['inform', 'retriev']\n",
      "[('3600', 0.11331550453842648), ('4181', 0.11331550453842648), ('4143', 0.06653418932705521), ('3691', 0.056103324776499486), ('147', 0.03291310976056385), ('5019', 0.02306791723529561), ('1269', 0.02215911601315055), ('5666', 0.021201316327423083), ('5564', 0.018899091606365274), ('2902', 0.01612952658674256)]\n",
      "Query tokens  ['comput', 'scienc']\n",
      "[('4012', 1.4276865117285158), ('4100', 0.15644898573787103), ('4096', 0.049367489007863904), ('4125', 0.039528817639340214), ('3993', 0.035260976873506746), ('3985', 0.03067018759711319), ('3981', 0.029167089324098498), ('3175', 0.028026552745486384), ('4093', 0.027494899357329454), ('3643', 0.026115238705398905)]\n",
      "Query tokens  ['uic']\n",
      "[('4012', 2.6658052109131845e-06), ('2555', 1.732037421049701e-06), ('377', 1.732037421049701e-06), ('1333', 4.886715569859026e-07), ('2511', 3.86712748023484e-07), ('4215', 3.4689552533707664e-07), ('4814', 3.3523122346099007e-07), ('3494', 2.9774872216165947e-07), ('5290', 2.2975420573683998e-07), ('2942', 2.0329283758576009e-07)]\n",
      "Query tokens  ['david', 'hay']\n",
      "[('3602', 0.19990252190176022), ('4183', 0.19990252190176022), ('5608', 0.0885923890567012), ('1316', 0.07565640817193876), ('1064', 0.07155610999203041), ('1302', 0.05038348735397295), ('885', 0.047170508895358974), ('3473', 0.02729451619795254), ('919', 0.023223924164971085), ('4126', 0.0226668478035012)]\n",
      "Query tokens  []\n",
      "\n",
      " No more results found !!\n",
      "[]\n",
      "Query tokens  []\n",
      "\n",
      " No more results found !!\n",
      "[]\n",
      "Query tokens  ['search', 'engin']\n",
      "[('4012', 0.877612399368343), ('3175', 0.06895694138651322), ('3494', 0.06543191785245704), ('3561', 0.06357291147152629), ('50', 0.059110410712252044), ('3580', 0.04571339311636924), ('3582', 0.04502680467702108), ('3201', 0.03718793841844604), ('3579', 0.03368488221723226), ('3497', 0.03272712470248196)]\n",
      "Query tokens  ['park']\n",
      "[('2896', 0.22148342690755332), ('2895', 0.17645388441535678), ('2293', 0.1674155588142684), ('442', 0.1674155588142684), ('2890', 0.1338634814974219), ('2893', 0.1281441883359644), ('1575', 0.10767240029596363), ('2837', 0.10767240029596363), ('2892', 0.1042895523232853), ('2894', 0.10295341236347709)]\n",
      "Query tokens  ['park', 'uic']\n",
      "[('2896', 0.22147852176331534), ('2895', 0.17644997653039), ('2293', 0.16741185126335445), ('442', 0.16741185126335445), ('2890', 0.1338605169839879), ('2893', 0.1281413502042228), ('1575', 0.1076700160161781), ('2837', 0.1076700160161781), ('2892', 0.10428724250248798), ('2894', 0.10295113223672545)]\n",
      "Query tokens  ['park', 'uic']\n",
      "[('2896', 0.22147852176331534), ('2895', 0.17644997653039), ('2293', 0.16741185126335445), ('442', 0.16741185126335445), ('2890', 0.1338605169839879), ('2893', 0.1281413502042228), ('1575', 0.1076700160161781), ('2837', 0.1076700160161781), ('2892', 0.10428724250248798), ('2894', 0.10295113223672545)]\n"
     ]
    }
   ],
   "source": [
    "window = Tk()\n",
    "window.title(\"Web Search Engine for UIC Domain\")\n",
    "window.geometry('800x800')\n",
    "\n",
    "welcome = Label(window, text=\"Welcome to UIC Search Engine, Enter your query below\")\n",
    "welcome.pack()\n",
    "\n",
    "txt = Entry(window, width=60)\n",
    "txt.pack()\n",
    "btn = Button(window, text='Search', command=searched)\n",
    "btn.pack()\n",
    "\n",
    "btn = Button(window, text=\"More results\", command=more_results)\n",
    "btn.pack()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cabce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
